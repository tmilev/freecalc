\begin{frame}
  \frametitle{Rate of Change}

  $O$: fixed point in space. For $P$ in space:
  $\textcolor[rgb]{0.98,0.00,0.00}{f(P) = |OP|^2}$

  Question: How does $f$ change around a point $P_0$ in space? \pause
  %
  $$\text{Change in } f = f(P) - f(P_0)$$
  %
  \pause \textcolor[rgb]{0.98,0.00,0.00}{Quantitative} question: \pause
  \textcolor[rgb]{0.98,0.00,0.00}{Rate of change} of $f$ at $P_0$

  \pause Ambiguity: \pause Rate of change of $f$ with respect to WHAT?
  %
  $$\text{ Rate of change } = \frac{f(P) - f(P_0)}{??}$$
  %
  \pause Naive answer: \pause With respect to
  \textcolor[rgb]{0.00,0.00,0.00}{distance} from $P_0$
  %
  $$\frac{f(P) - f(P_0)}{|P_0P|}$$
  %
  \pause Problem: \pause
  \textcolor[rgb]{0.98,0.00,0.00}{instantaneous rate of change}
  %
  $$\lim_{P\to P_0} \frac{f(P)-f(P_0)}{|P_0P|}$$
  %
  does not exist!
\end{frame}

\begin{frame}
  \frametitle{Rates of Change along Lines}

  $L$: line through $P_0(\textbf{r}_0)$.

  \pause
  \begin{center}
    How does $f(\textbf{r}) = |\textbf{r}|^2$
  change \textcolor[rgb]{0.98,0.00,0.00}{along $L$}?
  \end{center}

  \pause $\textbf{r} \colon \RR \to L$: smooth parametrization of $L$,
  $\textbf{r}(0) = \textbf{r}_0$
  %
  $$g\colon \RR \to \RR, \quad g(t) = f(\textbf{r}(t))$$
  %
  \begin{center}
    Rate of change of $f$ along $L$ = rate of change of $g$
  \end{center}

  \pause With respect to $t$:
  %
  $$\lim_{t\to 0} \frac{f(\textbf{r}(t))-f(\textbf{r}(0))}{t} =
  \lim_{t\to 0} \frac{g(t)-g(0)}{t} = g'(0)$$

  \pause Still ambiguous: \pause depends on the parametrization $\textbf{r}$.\pause

  Solution: \pause Arclength parametrization! \pause

  Almost solves the problem: \pause orientation still matters.
\end{frame}

\begin{frame}
  \frametitle{Directional Derivatives}

  $f \colon D \to \RR$, $P_0(\textbf{r}_0)$ in $D$,
  $\textbf{u}$ nonzero vector

  $L$: line through $P_0$ with direction $\textbf{u}$,
  \textcolor[rgb]{0.98,0.00,0.00}{oriented} by $\textbf{u}$.
  %
  $$\textbf{r}\colon \RR \to L, \quad \textbf{r}(t) =
  \textbf{r}_0+t\textbf{u}$$

  \pause \textcolor[rgb]{0.98,0.00,0.00}{Covariant derivative} -
  for \textcolor[rgb]{0.98,0.00,0.00}{nonzero} vector $\textbf{u}$:
  %
  $$(\nabla_{\textbf{u}} f) (P_0) = \lim_{t\to 0}
  \frac{f(\textbf{r}_0+t\textbf{u}) - f(\textbf{r}_0)}{t}$$

  \pause $\textbf{r}$: arclength parametrization \pause
  $\Longleftrightarrow$ $|\textbf{u}|=1$

  \pause \textcolor[rgb]{0.98,0.00,0.00}{Directional derivative} - for \textcolor[rgb]{0.98,0.00,0.00}{unit} vector
  $\textbf{u}$:
  %
  $$(D_{\textbf{u}} f)(P_0) =
  \lim_{t\to 0} \frac{f(\textbf{r}_0+t\textbf{u})-f(\textbf{r}_0)}{t}\; .$$

  \pause $(D_{\textbf{u}} f)(P_0)$ = instantaneous rate of change of $f$
  with respect to change in \emph{position} along the line
  with \textcolor[rgb]{0.98,0.00,0.00}{unit} direction $\textbf{u}$.
\end{frame}

\begin{frame}
  \frametitle{Partial Derivatives}

  $Oxy$: rectangular coordinate system in the plane

  $f\colon \mathcal{R} \to \RR$,  $P_0(x_0,y_0)$ inside $\mathcal{R}$
  %
  $$\textbf{u}=\textbf{i} \Longrightarrow \textbf{r}(t) = \textbf{r}_0 + t\textbf{u} = \langle x_0+t, y_0 \rangle$$
  %
  $$g(t) = f(\textbf{r}(t)) = f(x_0+t, y_0)= h(x_0+t)$$
  %
  where $h(x) = f(x,y_0)$ is a \emph{partial} function.\pause
  %
  $$(D_{\,\textbf{i}} f)(x_0,y_0) = \lim_{t\to 0} \frac{g(t)-g(0)}{t}
  =\lim_{t\to 0} \frac{h(x_0+t) -h(x_0)}{t} = h'(x_0)$$
  %
\pause Notations for \textcolor[rgb]{0.98,0.00,0.00}{partial derivatives}:
%
$$(D_{\,\textbf{i}}f)(x_0,y_0) = \frac{\partial f}{\partial x}(x_0,y_0) =
f_x(x_0,y_0)$$
%
$$(D_{\,\textbf{j}}f)(x_0,y_0) =  \frac{\partial f}{\partial y}(x_0,y_0) =
f_y(x_0,y_0)$$
%
\pause We compute partial derivatives by
\begin{itemize}
  \item keeping all other variables constant and
  \item applying the rules for differentiation for single variable functions.
\end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Example}
  Let $f(x,y) = y^2\ln{(2x+y)}- e^y$.

To compute $f_x$ \pause we treat $y$ as a constant.\pause
%
\begin{align*}
  f_x = \frac{\partial f}{\partial x} = & \frac{\partial(y^2\ln{(2x+y)}- e^y)}{\partial x} = \frac{\partial(y^2\ln{(2x+y)})}{\partial x} - \frac{\partial(e^y)}{\partial x} = \\
  %
  = & y^2 \frac{\partial(\ln{(2x+y)})}{\partial x} - 0 = y^2 \cdot \frac{1}{2x+y} \cdot \frac{\partial(2x+y)}{\partial x}= \frac{2y^2}{2x+y}\; .
\end{align*}

\pause To compute $f_y$ we treat $x$ as a constant:\pause
%
\begin{align*}
  f_y = \frac{\partial f}{\partial y} = & \frac{\partial(y^2\ln{(2x+y)}- e^y)}{\partial y} = \frac{\partial(y^2\ln{(2x+y)})}{\partial y} - \frac{\partial(e^y)}{\partial y} = \\
  %
  = & y^2 \frac{\partial(\ln{(2x+y)})}{\partial y} +\frac{\partial(y^2)}{\partial y} \ln{(2x+y)}
   - e^y = \\
   %
   = & y^2 \cdot \frac{1}{2x+y} \cdot \frac{\partial(2x+y)}{y} +2y\ln{(2x+y)} - e^y = \\
   %
   = & \frac{y^2}{2x+y} +2y\ln{(2x+y)} - e^y \; .
\end{align*}
\end{frame}

\begin{frame}
\frametitle{Graphical Interpretation}

The graph of $f$ is the surface
%
$$(x,y) \to  \langle x,y, f(x,y) \rangle$$

The vertical plane containing the line $\textbf{r}=\textbf{r}_0 + t\textbf{i}$ is the plane $y=y_0$.

Intersection of graph with the plane $y=y_0$ is the curve
%
$$\gamma(t) = \langle t, y_0, f(t,y_0) \rangle \Longrightarrow \text{ Graph of } z=h(x)$$
%
Direction of tangent line to $\gamma$:
%
$$\gamma'(x_0) = \langle 1,0,f_x(x_0,y_0) \rangle$$

In the $xz-$plane $y=y_0$, the slope of this line is
%
$$h'(x_0) = f_x(x_0,y_0)$$
\end{frame}

\begin{frame}
  \frametitle{Higher Order Derivatives}
  Partial derivative functions:
%
$$(x,y) \to f_x(x,y) \qquad \text{ and } \qquad  (x,y) \to f_y(x,y)\; ,$$
%
\pause The partial derivatives of the partial derivatives $f_x$ and $f_y$ are called \emph{the second order partial derivatives} of $f$.

\pause The partial derivatives of the second order derivatives are the \emph{third order} derivatives, and so on.

$$f(x,y) \to \left\{ \begin{array}{cc}
  \frac{\partial f}{\partial x}=f_x  \to & \left\{ \begin{array}{ccc}
    \frac{\partial}{\partial x} \left( \frac{\partial f}{\partial x} \right) = & \frac{\partial^2 f}{\partial x^2} = & f_{xx} \\
    %
    & & \\
    %
    \frac{\partial}{\partial y} \left( \frac{\partial f}{\partial x} \right) = & \frac{\partial^2 f}{\partial y\,\partial x} = & f_{xy}
  \end{array} \right. \\
  & \\
  \frac{\partial f}{\partial x}=f_y  \to & \left\{ \begin{array}{ccc}
    \frac{\partial}{\partial x} \left( \frac{\partial f}{\partial y} \right) = & \frac{\partial^2 f}{\partial x\, \partial y} = & f_{yx} \\
    %
    & & \\
    %
    \frac{\partial}{\partial y} \left( \frac{\partial f}{\partial y} \right) = & \frac{\partial^2 f}{\partial y^2} = & f_{yy}
  \end{array} \right.
\end{array} \right.$$
\end{frame}

\begin{frame}
  \frametitle{Example}

  $f(x,y) = x^2y^3$. Then\pause
%
\begin{align*}
  f_x(x,y) = 2xy^3 \quad & \quad f_{y}(x,y) = 3x^2y^2 \\
  %
  f_{xx}(x,y) = (2xy^3)_x = 2y^3 \quad & \quad f_{xy}(x,y) = (2xy^3)_y = 6xy^2 \\
  %
  f_{yx}(x,y) = (3x^2y^2)_x = 6xy^2 \quad & \quad f_{yy}(x,y) = (3x^2y^2)_y = 6x^2y
\end{align*}

\pause Notice that $f_{xy} = f_{yx}$. That is not a coincidence.

\begin{theorem}[Clairaut] If the second order derivatives $f_{xy}$ and $f_{yx}$ are continuous on an open domain (such as an open disk, for example), then they are equal everywhere on the domain.
\end{theorem}

Similar results for functions of three variables.
\end{frame}

\begin{frame}
  \frametitle{Tangent Plane}

Given a surface $S$ in space and a point $P$ on the surface.

\bigskip

\underline{Question:} What should be the geometric plane tangent to $S$ at $P$?

\pause
\bigskip

\underline{Intuitively}: It should include all vectors tangent at $P$ to curves passing through $P$ and contained in the surface.

\bigskip

\underline{Equivalently}: It should be the geometric plane
\begin{itemize}
  \item passing through $P$;
  \item parallel to the directions of all tangent vectors of curves passing through $P$ and contained in the surface.
\end{itemize}

\end{frame}

\begin{frame}
  \frametitle{Tangent Plane to a Graph Surface}

Graph surface $z=f(x,y)$, point $P(x_0,y_0,z_0)$ on the surface.

Particular curves through $P$:\pause graphs of partial functions.
%
\begin{align*}
  x \to \langle x,y_0, f(x,y_0) \rangle & \Longrightarrow \text{ tangent direction } \langle 1,0,f_x(x_0,y_0)\rangle \\
%
     y\to \langle x_0,y, f(x_0,y) \rangle & \Longrightarrow \text{ tangent direction } \langle 0,1,f_y(x_0,y_0)\rangle \; .
\end{align*}

Vector normal to the tangent plane:\pause
%
$$
  \textbf{n} =  \langle 1,0,f_x(x_0,y_0)\rangle \times \langle 0,1,f_y(x_0,y_0)\rangle =
\langle -f_x(x_0,y_0), -f_y(x_0,y_0), 1 \rangle\; .
$$
%
Equation of the tangent plane at $P_0(x_0,y_0,z_0=f(x_0,y_0))$:
%
$$\textbf{n} \cdot (\textbf{r}-\textbf{r}_0) = 0 \Longleftrightarrow$$
%
$$-f_x(x_0,y_0) (x-x_0) -f_y(x_0,y_0)(y-y_0) + (z-f(x_0,y_0)) = 0 \Longleftrightarrow $$
%
$$\boxed{ \; z= f(x_0,y_0) + f_x(x_0,y_0) (x-x_0) + f_y(x_0,y_0)(y-y_0) \; }\; .$$
%
\end{frame}

\begin{frame}
  \frametitle{Linearizations}
$$\boxed{ \; z= f(x_0,y_0) + f_x(x_0,y_0) (x-x_0) + f_y(x_0,y_0)(y-y_0) \; }\; .$$
%
$$L_{f,(x_0,y_0)} (x,y) = f(x_0,y_0) + f_x(x_0,y_0) (x-x_0) + f_y(x_0,y_0)(y-y_0)$$
%
is called the \textcolor[rgb]{0.98,0.00,0.00}{linearization} of $f$ at $(x_0,y_0)$.

\pause
\underline{Example}: Tangent plane to $z=x^2+xy+2y^2$

at the point corresponding to $(x,y) = (4,1)$.

Function $f(x,y) = x^2+xy+2y^2$. \pause Corresponding $z$ value:
%
$$f(4,1) = 16+4+2 = 22$$
%
\pause Partial derivatives \textcolor[rgb]{0.98,0.00,0.00}{at $(4,1)$}:
%
\begin{align*}
  f_x(x,y) = 2x+y & \Longrightarrow f_x(4,1) = 9 \\
  %
  f_y(x,y) = x+4y & \Longrightarrow f_y(4,1) = 8
\end{align*}
%
\pause Equation of tangent plane:
%
$$z = 22+ 9(x-4) + 8 (y-1) \Longleftrightarrow z = 9x+8y -22$$
%
\pause Linearization:
%
$$L_{f, (4,1)}(x,y) = 22+ 9(x-4) + 8 (y-1) = 9x+8y -22\; .$$
%
\end{frame}

\begin{frame}
  \frametitle{Good Linear Approximations}

The linearization provides an \emph{approximation} of a function around a point.

\underline{Question}: How does the error in output, $|f(x,y) - L_{f,(x_0,y_0)}|$, compare to the error in input, $\sqrt{(x-x_0)^2 + (y-y_0)^2}$, for small errors in input?

\pause Limit of ratio:
%
$$\lim_{(x,y) \to (x_0,y_0)} \frac{|f(x,y) - L_{f,(x_0,y_0)}|}{\sqrt{(x-x_0)^2 + (y-y_0)^2}}$$

\pause In our example, using $x=4+r\cos{\theta}$, $y=1+r\sin{\theta}$:
%
$$\lim_{(x,y) \to (4,1)} \frac{|x^2+xy+2y^2 - (9x+8y -22)|}{\sqrt{(x-4)^2+(y-1)^2}} = 0$$
%

\pause \underline{Definition}: A linear polynomial $P(x,y) = ax+by+c$ is called a \textcolor[rgb]{0.98,0.00,0.00}{good linear approximation} for $f(x,y)$ around the point $(x_0,y_0)$ if
%
$$\lim_{(x,y) \to (x_0,y_0)} \frac{|f(x,y) - P(x,y)|}{\sqrt{(x-x_0)^2 + (y-y_0)^2}} = 0\; .$$

\pause \underline{Conclusion}: $P(x,y) = 9x+8y-22$ is a good linear approximation for $f(x,y) = x^2+xy+2y^2$ around $(4,1)$.
\end{frame}



\begin{frame}
  \frametitle{Differentiability}

If $y=h(x)$ is a function of one variable, then
%
$$L_{h,x_0}(x) = h(x_0) + h'(x_0) (x-x_0)$$
%
$$
  \lim_{x\to x_0} \frac{|h(x)-L_{h,x_0}(x)|}{|x-x_0|} = \lim_{x \to x_0} \left| \frac{h(x)-h(x_0)}{x-x_0} -h'(x_0) \right| = 0
$$
%
\pause \underline{One variable}: the linear approximation is a good approximation.

\pause \underline{Several variables}:

$f_x(x_0,y_0)$, $f_y(x_0,y_0)$ exist $\Longrightarrow$
$f$ has a linear approximation $L_{f, (x_0,y_0)}$.

But is that a \emph{good} linear approximation? \pause
Unfortunately, \textcolor[rgb]{0.98,0.00,0.00}{not always}!

\medskip

\pause \underline{Definition}: A function $f$ is called \textcolor[rgb]{0.98,0.00,0.00}{differentiable at a point} $(x_0,y_0)$ if it has a good linear approximation at $(x_0,y_0)$.

\medskip

\pause Example: $f(x,y) = x^2+xy+2y^2$ is differentiable at $(4,1)$.

\medskip

\pause \underline{Fact}: If $f$ has a good linear approximation at $(x_0,y_0)$, then the good linear approximation is necessarily the linearization of $f$ at $(x_0,y_0)$.
\end{frame}



\begin{frame}
  \frametitle{Continuity and Differentiability}

  \underline{Single variable functions}:

  differentiable at a point if and only if it has a derivative at that point.

  \medskip

  has derivative at a point $\Longrightarrow$ is continuous at the point
  \bigskip

\pause   \underline{Several variable functions}:

\begin{itemize}
  \item If $f$ is differentiable at $(x_0,y_0)$, then:
  %
  \begin{itemize}
    \item $f$ is continuous at $(x_0,y_0)$;
    \item $f$ has partial derivatives at $(x_0,y_0)$.
  \end{itemize}
  %
  \item  If $f$ has partial derivatives at $(x_0,y_0)$ then
  %
  \begin{itemize}
    \item $f$ \textcolor[rgb]{0.98,0.00,0.00}{need not} be differentiable at $(x_0,y_0)$;
    \item $f$ \textcolor[rgb]{0.98,0.00,0.00}{need not be even continuous} at $(x_0,y_0)$.
  \end{itemize}
\end{itemize}
\end{frame}



\begin{frame}
  \frametitle{Good News!}

  Source of these problems:
\begin{itemize}
  \item Partial derivatives at a point take into consideration the behavior of the function along \emph{special directions};
  %
  \item Continuity and differentiability require at least \emph{all directions}.
\end{itemize}

\pause \underline{Positive} result:

\begin{theorem}
   If $f_x$ and $f_y$ exist and are continuous on an open disk, then $f$ is differentiable at all points of that disk.
\end{theorem}

\pause \underline{Consequences}:
\begin{itemize}
  \item Polynomial functions are differentiable;
  \item Algebraic combinations of differentiable functions are differentiable.
\end{itemize}
\end{frame}


\begin{frame}
  \frametitle{Total Differential}

If $f$ is differentiable at $(x_0,y_0)$, then
%
$$f(x,y) \simeq f(x_0,y_0)+ f_x(x_0,y_0)(x-x_0) + f_y(x_0,y_0) (y-y_0)$$
%
$$\Delta f \simeq f_x(x_0,y_0) \Delta x + f_y(x_0,y_0) \Delta y$$

\pause For infinitesimally small $\Delta x$ and $\Delta y$ we get:

\underline{Definition}: The \textcolor[rgb]{0.98,0.00,0.00}{total differential} $df$ at $(x_0,y_0)$ is
%
$$\left. (df) \right|_{(x_0,y_0)} = f_x(x_0,y_0) dx + f_y(x_0,y_0) dy$$
%
\pause Alternatively:
%
$$df = f_x dx + f_y dy \qquad \text{ or } \qquad  df = f_x dx + f_y dy + f_z dz$$
%
\begin{align*}
  \Delta f: & \text{ actual change in } f\\
  %
  df \simeq \Delta f: & \text{ infinitesimal change in } f\\
  %
  f_x(x_0,y_0), f_y(x_0,y_0): & \text{ error propagation factors }
\end{align*}

\end{frame}

\begin{frame}
  \frametitle{Application}

  A cylinder has radius $r=3cm$ and height $h=5cm$. The error in measuring the radius is $\pm 1 mm$, and the error in measuring the height is $\pm 1 mm$. Estimate the error in the volume of the cylinder.
\pause
\bigskip

$V(r,h) = \pi r^2 h$. The actual volume: $V(3,5) = 45\pi \, cm^3$.

\pause
The error in volume, $\Delta V$, is estimated by $dV$:
%
$$\Delta V \simeq dV = V _r(3,5) dr + V_h(3,5) dh \simeq V _r(3,5) \Delta r + V_h(3,5) \Delta h\; .$$
%
$$V_r(r,h) = 2\pi r h \Longrightarrow V_r(3,5) = 30 \pi$$
%
$$V_h(r,h) = \pi r^2 \Longrightarrow V_h(3,5) = 9\pi$$
%
$$\Delta V  \simeq (30\pi) (\pm 0.1) + ((9\pi)(\pm 0.1) \Longrightarrow V(r,h) \simeq V(3,5) \pm 3.9\pi \, cm^3$$

The error in volume is $\pm 3.9\pi \, cm^3$.

\pause
Relative error:
%
$$\frac{\Delta V}{V} \simeq \pm \frac{3.9 \pi}{45\pi} \simeq \pm 8.6\%$$

\medskip
\pause
\underline{Remark}: Since $V_r(3,5) > V_h(3,5)$, the result is more sensitive to errors in $r$ than to errors in $h$.
\end{frame}

\begin{frame}
  \frametitle{Motivation}

Recall:
\begin{itemize}
  \item $f$, differentiable function,
  \item $\textbf{u}=\langle u_1,u_2,u_3 \rangle$, unit vector,
  \item $P(x_0,y_0,z_0)$, point.
\end{itemize}
%
What is the rate of change of $f$ at $P$ in the direction $\textbf{u}$?

\pause
Directional derivative
%
$$(D_{\textbf{u}}f)(P) = \left. \frac{d}{dt}\right|_{t=0} f(x_0+tu_1, y_0+tu_2,z_0+tu_3)$$
%
\pause
More general, if
\begin{itemize}
\item $w=w(x,y,z)$;
\item $x=x(t)$, $y=y(t)$, $z=z(t)$,
\end{itemize}
%
and all the functions are differentiable, how do we compute $\frac{dw}{dt}$?
\end{frame}

\begin{frame}
  \frametitle{Chain Rule}
Differentials
%
$$dw=w_x(x,y,z)\textcolor[rgb]{0.98,0.00,0.00}{dx} +
w_y(x,y,z)\textcolor[rgb]{0.00,0.00,1.00}{dy}+
w_z(x,y,z)\textcolor[rgb]{0.00,0.50,0.00}{dz}$$
%
and
%
$$\textcolor[rgb]{0.98,0.00,0.00}{dx=x'(t)dt} \qquad
\textcolor[rgb]{0.00,0.00,1.00}{dy = y'(t)dt} \qquad
\textcolor[rgb]{0.00,0.50,0.00}{dz=z'(t)dt} \; .$$
%
\pause Then
%
$$dw = \left( w_x(x,y,z) x'(t) + w_y(x,y,z) y'(t) +
w_z(x,y,z) z'(t) \right) dt$$
%
\pause
Therefore
%
$$\frac{dw}{dt}(t) = \frac{\partial w}{\partial x}(x,y,z) \frac{dx}{dt}(t) +
\frac{\partial w}{\partial y}(x,y,z) \frac{dy}{dt}(t) +
\frac{\partial w}{\partial z}(x,y,z) \frac{dz}{dt}(t)$$

\pause
Derivative of composition of functions $\Longrightarrow$ \textcolor[rgb]{0.98,0.00,0.00}{Chain Rule}
\end{frame}

\begin{frame}
  \frametitle{Tree Diagrams}
\begin{itemize}
\item $w=w(x,y,z)$;
\item $x=x(t)$, $y=y(t)$, $z=z(t)$,
\end{itemize}
%
$$\frac{dw}{dt}(t) =
\textcolor[rgb]{0.98,0.00,0.00}{\frac{\partial w}{\partial x}(x,y,z) \frac{dx}{dt}(t)}+ \textcolor[rgb]{0.00,0.00,1.00}{\frac{\partial w}{\partial y}(x,y,z) \frac{dy}{dt}(t)}+
\textcolor[rgb]{0.00,0.50,0.00}{\frac{\partial w}{\partial z}(x,y,z) \frac{dz}{dt}(t)}$$
%
Alternative way of arranging terms - tree diagram:
%
$$
\xymatrix{
 & w  &  \\
\textcolor[rgb]{0.98,0.00,0.00}{x} \ar[ur] &
\textcolor[rgb]{0.00,0.00,1.00}{y} \ar[u] &
\textcolor[rgb]{0.00,0.50,0.00}{z} \ar[ul] \\
\textcolor[rgb]{0.98,0.00,0.00}{t} \ar[u]&
\textcolor[rgb]{0.00,0.00,1.00}{t} \ar[u]&
\textcolor[rgb]{0.00,0.50,0.00}{t}\ar[u]
}
$$

\end{frame}

\begin{frame}
  \frametitle{(More) General Chain Rule}

More general formula:
%
\begin{itemize}
\item $w=F(x,y,z)$;
\item $x=f(u,v)$, $y=g(u,v)$, $z=h(u,v)$.
\end{itemize}
%
$$w = F(f(u,v), g(u,v), h(u,v)) = G(u,v)$$
%
To compute $\frac{\partial w}{\partial u} = \frac{\partial G}{\partial u}$:

\begin{itemize}
  \item arrange variables in a tree diagram:
  %
  $$\xymatrix{
  & & & & w &  & & \\
  & x  \ar[urrr]^F & & & y \ar[u]^F & & &  z \ar[ulll]_F & \\
  u \ar[ur]^f & & v\ar[ul]_f & u \ar[ur]^g & & v \ar[ul]_g & u \ar[ur]^h & & v \ar[ul]_h
  }$$
  %
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{(More) General Chain Rule}
Arrange variables in a tree diagram:
  %
  $$\xymatrix{
  & & & & w &  & & \\
  & x  \ar[urrr]^F & & & y \ar[u]^F & & &  z \ar[ulll]_F & \\
  u \ar[ur]^f & & v\ar[ul]_f & u \ar[ur]^g & & v \ar[ul]_g & u \ar[ur]^h & & v \ar[ul]_h
  }$$
  %
  \begin{overlayarea}{\textheight}{5cm}
  \only<2>{
  \begin{itemize}
  \item Think of each edge $a \stackrel{H}{ \to} b$ as having a label $\frac{\partial b}{\partial a} = \frac{\partial H}{\partial a}$;
  %
  \item Identify all the end vertices that are labeled $u$;
  %
  \item Identify all the paths connecting an end vertex $u$ to the root $w$. In our case there are three such paths:
      \begin{itemize}
        \item $u \to x \to w$;
        \item $u \to y \to w$;
        \item $u \to z \to w$.
      \end{itemize}
  \end{itemize}
  }
  \only<3>{
    For each path add a term consisting of product of (partial) derivatives along edges. In our case:
      %
      \begin{align*}
        \text{First path contribution: } \quad & \frac{\partial w}{\partial x} \cdot \frac{\partial x}{\partial u} = \frac{\partial F}{\partial x} \cdot \frac{\partial f}{\partial u}\\
        %
        \text{Second path contribution: } \quad & \frac{\partial w}{\partial y} \cdot \frac{\partial y}{\partial u} = \frac{\partial F}{\partial y} \cdot \frac{\partial g}{\partial u}\\
        %
        \text{Third path contribution: } \quad & \frac{\partial w}{\partial z} \cdot \frac{\partial z}{\partial u} = \frac{\partial F}{\partial z} \cdot \frac{\partial h}{\partial u}
      \end{align*}
  }
  \only<4>{
  The derivative is the sum of the contributions along paths:
  %
  \begin{align*}
    \frac{\partial w}{\partial u} = \frac{\partial G}{\partial u} = & \frac{\partial w}{\partial x} \cdot \frac{\partial x}{\partial u} + \frac{\partial w}{\partial y} \cdot \frac{\partial y}{\partial u}+ \frac{\partial w}{\partial z} \cdot \frac{\partial z}{\partial u} = \\
    = & \frac{\partial F}{\partial x} \cdot \frac{\partial f}{\partial u}+\frac{\partial F}{\partial y} \cdot \frac{\partial g}{\partial u}+ \frac{\partial F}{\partial z} \cdot \frac{\partial h}{\partial u}
  \end{align*}
  }
  \end{overlayarea}
\end{frame}

\begin{frame}
  \frametitle{Example: powerexponential}

   Let $f(x) = x^x$. Compute $f'(x)$.

\begin{itemize}
  \item Calculus I method: logarithmic differentiation.
  \item Calculus III method: chain rule.
\end{itemize}

\pause
Let $w=w(u,v) = u^v$ and $u=u(x) = x$, $v=v(x) = x$.
%
$$
\xymatrix{
 & w  &  \\
u \ar[ur] & &  v \ar[ul] \\
x \ar[u]&  & x \ar[u]
}
$$
\pause
Then $f(x) = w(u(x),v(x))$ and
%
$$f'(x) = \frac{\partial w}{\partial u} \frac{du}{dx} + \frac{\partial w}{\partial v} \frac{dv}{dx} = vu^{v-1} + u^v\ln{u} = x\cdot x^{x-1} + x^x\ln{x} = x^x (1+\ln{x})\; .$$

\end{frame}

\begin{frame}
  \frametitle{Example: Derivatives in polar coordinates}

Let $z=f(x,y)$ and $x=r\cos\theta$, $y=r\sin\theta$. Then
%
$$z=f(r\cos\theta, r\sin\theta) = g(r, \theta) \; .$$
%
$P(x,y) = P(r,\theta)$. Compute $\frac{\partial z}{\partial r} = \frac{\partial g}{\partial r}$ at $P$:
%
$$\xymatrix{
 &   &        & z &    &   & \\
 & x \ar[urr] &        &   &    & y \ar[ull] & \\
r\ar[ur]&   & \theta \ar[ul]&   &  r\ar[ur] &   & \theta \ar[ul]
}$$
%
Then:
%
$$
  \frac{\textcolor[rgb]{0.98,0.00,0.00}{\partial} z}{\textcolor[rgb]{0.98,0.00,0.00}{\partial r}} (P) = \frac{\partial z}{\partial x} (P)\frac{\partial x}{\partial r} + \frac{\partial z}{\partial y}(P) \frac{\partial y}{\partial r} = \frac{\textcolor[rgb]{0.98,0.00,0.00}{\partial} z}{\textcolor[rgb]{0.98,0.00,0.00}{\partial x}}(P) \cos\theta + \frac{\textcolor[rgb]{0.98,0.00,0.00}{\partial} z}{\textcolor[rgb]{0.98,0.00,0.00}{\partial y}} (P) \sin\theta
$$
%
hence
%
$$\frac{\partial}{\partial r} = \cos\theta\frac{\partial }{\partial x}  + \sin\theta\frac{\partial }{\partial y} $$
\end{frame}

\begin{frame}
  \frametitle{Partial Derivatives in Polar Coordinates}
%
$$\frac{\partial}{\partial r} = \cos\theta\frac{\partial }{\partial x}  + \sin\theta\frac{\partial }{\partial y} $$
%
$$  \frac{\partial}{\partial \theta} =  - r \sin\theta\frac{\partial }{\partial x}  + r \cos\theta\frac{\partial }{\partial y} \; .$$

\pause
Solving the linear system we get:

$$
  \frac{\partial}{\partial x} = \cos\theta\frac{\partial }{\partial r}  - \frac{1}{r} \sin\theta\frac{\partial }{\partial \theta} $$
%
$$\frac{\partial}{\partial y} = \sin\theta\frac{\partial }{\partial r}  + \frac{1}{r} \cos\theta\frac{\partial }{\partial \theta}
$$
\end{frame}

\begin{frame}
  \frametitle{The Laplace Operator}
Differential Operator:
\begin{itemize}
  \item Input: function
  \item Output: function
  \item Method: algebraic operations and differentiation
\end{itemize}

\pause
Laplace operator:
%
$$z \to \Delta z = \frac{\partial^2 z}{\partial x^2} +\frac{\partial^2 z}{\partial y^2} \Longrightarrow \Delta = \frac{\partial^2 }{\partial x^2} +\frac{\partial^2 }{\partial y^2}$$

\pause
In polar coordinates:
%
$$\Delta = \frac{1}{r}\frac{\partial}{\partial r} \left( r\frac{\partial }{\partial r} \right) +  \frac{1}{r^2}\frac{\partial^2 }{\partial \theta^2}\; .$$
\end{frame}

\begin{frame}
  \frametitle{Harmonic Functions}

\underline{Definition}: Functions $f$ such that $\Delta f=0$ are called \emph{harmonic} functions.
\pause
\smallskip

\underline{Example:} The function $f(x,y) = \ln{(x^2+y^2)}$ is a harmonic function.
\pause

%
$$f(x,y) = g(r,\theta) = \ln{(r^2)} = 2\ln r \; .$$
%
Then
%
\begin{align*}
  \Delta f = \Delta g = & \frac{1}{r}\frac{\partial }{\partial r} \left( r\frac{\partial g }{\partial r} \right) +  \frac{1}{r^2}\frac{\partial^2 g}{\partial \theta^2} = \frac{1}{r}\frac{\partial }{\partial r} \left( r\frac{\partial (2\ln{r}) }{\partial r} \right) +  \frac{1}{r^2}\frac{\partial^2 (2\ln{r})}{\partial \theta^2} \\
  = & \frac{1}{r}\frac{\partial }{\partial r} \left( r \cdot \frac{2}{r} \right) = \frac{1}{r}\frac{\partial }{\partial r} (2) = 0\; .
\end{align*}

\pause
\underline{Fact}: The only harmonic functions independent of $\theta$ are of the form
%
$$g(r,\theta) = c_1\ln{r}+c_2 \; .$$
\end{frame}

\begin{frame}
  \frametitle{Directional Derivatives}

Recall:
\begin{itemize}
  \item $f$, differentiable function,
  \item $\textbf{u}=\langle u_1,u_2,u_3 \rangle$, unit vector,
  \item $P(x_0,y_0,z_0)$, point.
\end{itemize}
%
What is the rate of change of $f$ at $P$ in the direction $\textbf{u}$?

\pause
Directional derivative
%
$$(D_{\bm{u}}f)(P) = \left. \frac{d}{dt}\right|_{t=0} f(x_0+tu_1, y_0+tu_2,z_0+tu_3)$$  \end{frame}

\begin{frame}
  \frametitle{}
%
$w =f(x,y,z)$ and
%
\begin{align*}
  x = & x_0 + tu_1 \\
  y = & y_0 + tu_2 \\
  z = & z_0 + tu_3
\end{align*}
%
\pause
%
\begin{align*}
  \frac{dw}{dt} = & \frac{\partial f}{\partial x}(x,y,z) \frac{dx}{dt} + \frac{\partial f}{\partial y}(x,y,z) \frac{dy}{dt} + \frac{\partial f}{\partial z}(x,y,z) \frac{dz}{dt} = \\
  = & \frac{\partial f}{\partial x}(x,y,z) u_1 + \frac{\partial f}{\partial y}(x,y,z) u_2 + \frac{\partial f}{\partial z}(x,y,z) u_3 = \\
  = & \langle \frac{\partial f}{\partial x}(x,y,z) , \frac{\partial f}{\partial y}(x,y,z), \frac{\partial f}{\partial z}(x,y,z)\rangle \cdot \textbf{u}
\end{align*}
%
\pause
Let
%
$$\textbf{W}_{f,(x_0,y_0,z_0)} =\langle \frac{\partial f}{\partial x}(x_0,y_0,z_0) , \frac{\partial f}{\partial y}(x_0,y_0,z_0), \frac{\partial f}{\partial z}(x_0,y_0,z_0)\rangle$$
%
\pause
Then
%
$$(D_{\textbf{u}}f)(x_0,y_0,z_0) = \left. \frac{dw}{dt}\right|_{t=0} = \textbf{W}_{f,(x_0,y_0,z_0)} \cdot \textbf{u}\; .$$
\end{frame}

\begin{frame}
\frametitle{Example}

Directional derivative
\begin{itemize}
  \item of function $f(x,y,z) = \ln{(x^2+2y^2-z^2)}$;
  \item at the point $P(2,1,-1)$;
  \item in the direction $\textbf{v}=\langle -1,2,1\rangle$.
\end{itemize}
\pause
A unit vector in the direction of $\textbf{v}$ is
%
$$\textbf{u} = \frac{1}{|\textbf{v}|} \textbf{v} = \frac{1}{\sqrt{6}} \langle -1,2,1\rangle\; .$$
%
\begin{overlayarea}{\textheight}{5cm}
\only<3>{The partial derivatives are
%
\begin{align*}
  \frac{\partial f}{\partial x} = \frac{2x}{x^2+2y^2-z^2} & \Longrightarrow \frac{\partial f}{\partial x}(2,1,-1) = \frac{4}{5} \\
  %
  \frac{\partial f}{\partial y} = \frac{4y}{x^2+2y^2-z^2} & \Longrightarrow \frac{\partial f}{\partial y}(2,1,-1) = \frac{4}{5} \\
  %
  \frac{\partial f}{\partial z} = \frac{-2z}{x^2+2y^2-z^2} & \Longrightarrow \frac{\partial f}{\partial z}(2,1,-1) = \frac{2}{5}
\end{align*}
%
$$\textbf{W}_{f,(2,1,-1)} = \langle \frac{4}{5}, \frac{4}{5}, \frac{2}{5}\rangle$$}
%
\only<4->{
%
$$\textbf{W}_{f,(2,1,-1)} = \langle f_x(2,1,-1), f_y(2,1,-1), f_z(2,1,-1) \rangle = \langle \frac{4}{5}, \frac{4}{5}, \frac{2}{5}\rangle$$
%
$$(D_{\textbf{u}}f)(2,1,-1) = \textbf{W}_{f,(2,1,-1)} \cdot \textbf{u} = \frac{\sqrt{6}}{5}$$

$(D_{\textbf{u}}f)(2,1,-1)>0 \Longrightarrow$ \pause if we start at $(2,1,-1)$ and move in the direction $\textbf{u}$, then $f$ is increasing.}
  \end{overlayarea}
\end{frame}

\begin{frame}
  \frametitle{Gradient}
  Given a function $f$ and a point $P$:
\begin{itemize}
  \item What is the direction in which $f$ increases the fastest from $P$?
  \item What is that maximal rate of increase?
\end{itemize}
%
\pause
\underline{Fact}: If the maximal rate of increase is strictly positive, then it is achieved in exactly one direction. \pause The answers are encoded in a vector.

\begin{definition}
   The \emph{gradient vector} of $f$ at $P$ is the unique vector that has
\begin{itemize}
  \item magnitude equal to the maximal rate of increase of $f$ from $P$.
  \item If the magnitude is not zero, then the direction is the direction in which $f$ increases the fastest from $P$.
\end{itemize}
\end{definition}
%
Notation: $(\nabla f)(P) = (\nabla f)_P = (\textbf{grad} \;f)(P)$

\begin{itemize}
  \item $\nabla f$: gradient vector field \hspace{2cm}
$P \rightsquigarrow (\nabla f)(P)$
%
\item $\nabla$: \emph{del} operator \hspace{2cm}
function $f$ $\rightsquigarrow$ vector field $\nabla f$
\end{itemize}

\end{frame}

\begin{frame}
  \frametitle{Coordinate Computation}

  If $\textbf{u}$ is a unit vector then:
%
$$
  (D_{\textbf{u}}f)(x_0,y_0,z_0) =  \textbf{W}_{f,(x_0,y_0,z_0)} \cdot \textbf{u} = |\textbf{W}_{f,(x_0,y_0,z_0)}| \cos\alpha \; .
$$
%
\pause If $|\textbf{W}_{f,(x_0,y_0,z_0)}|\neq 0$, then
%
\begin{itemize}
  \item $(D_{\textbf{u}}f)(x_0,y_0,z_0)$ is maximal when $\alpha = 0$, hence if
      $$\textbf{u} = \frac{1}{|\textbf{W}_{f,(x_0,y_0,z_0)}|}\,\textbf{W}_{f,(x_0,y_0,z_0)}$$
%
  \item The maximal value of $(D_{\textbf{u}}f)(x_0,y_0,z_0)$ is $|\textbf{W}_{f,(x_0,y_0,z_0)}|$.
\end{itemize}

\pause Therefore, in rectangular coordinates, we have
%
\begin{align*}
  (\nabla f)(x_0,y_0,z_0) = & |\textbf{W}_{f,(x_0,y_0,z_0)}| \textbf{u} = \textbf{W}_{f,(x_0,y_0,z_0)} = \\
  %
  = & \langle \frac{\partial f}{\partial x}(x_0,y_0,z_0) , \frac{\partial f}{\partial y}(x_0,y_0,z_0), \frac{\partial f}{\partial z}(x_0,y_0,z_0) \rangle
\end{align*}
%
\pause Coordinate-free formula for directional derivatives:
%
$$(D_{\textbf{u}} f)(P) = (\nabla f)_P \cdot \textbf{u}$$
\end{frame}

\begin{frame}
  \frametitle{Covariant Derivative}

  Directional derivative =rate of change along straight line

\pause
  More general setting:
  \begin{itemize}
    \item $f$: a differentiable function
    \item $\gamma$: a smooth parametric curve
  \end{itemize}

\pause
Question: How does $f$ change as we move along $\gamma$?

\begin{definition}
  The rate of change of $f(\gamma(t))$ with respect to $t$ is called the \emph{covariant derivative} of $f$ along $\gamma$ and is denoted by $\nabla_{\gamma'} f$.
\end{definition}

\pause
Using the chain rule we get
%
$$(\nabla_{\gamma'(t_0)} f) (\gamma(t_0)) = \left. \frac{d}{dt}\right|_{t=t_0} f(\gamma(t)) = (\nabla f)_{\gamma(t_0)} \cdot \gamma'(t_0) \; .$$
%

\pause
If $\textbf{u}$ is a unit vector,  $\gamma(t_0) = P$ and $\gamma'(t_0) = \textbf{u}$, then:
%
$$(D_{\textbf{u}} f)(P) = (\nabla f)_P \cdot \textbf{u} =
(\nabla f)_{\gamma(t_0)} \cdot \gamma'(t_0) = \left. \frac{d}{dt}\right|_{t=t_0} f(\gamma(t))\; .$$
%
\end{frame}

\begin{frame}
  \frametitle{Gradient in Polar Coordinates}
  $\textbf{e}_r=\textbf{e}_r(P)$ and $\textbf{e}_\theta=\textbf{e}_\theta(P)$ are the polar fundamental directions at $P$
%
$$(\nabla f)_P = a \textbf{e}_r + b \textbf{e}_\theta$$
%
\pause
$\textbf{e}_r$ and $\textbf{e}_\theta$ perpendicular unit vectors $\Longrightarrow$
%
\begin{align*}
  a=& (\nabla f)_P \cdot \textbf{e}_r = (D_{\textbf{e}_r} f)(P) \\
  %
  b=& (\nabla f)_P \cdot \textbf{e}_\theta = (D_{\textbf{e}_\theta} f)(P)
\end{align*}
%
\begin{overlayarea}{\textheight}{5cm}
\only<3>{
To compute $(D_{\textbf{e}_r} f)(P)$ we use the line through $P(r_0,\theta_0)$ with direction $\textbf{e}_r$, which in polar coordinates is given by $(r,\theta) = (t,\theta_0)$. Therefore
%
$$a = (D_{\textbf{e}_r} f)(P) = \left. \frac{d}{dt}\right|_{t=r_0} f(t,\theta_0) = \frac{\partial f}{\partial r}(P)\; .$$}
%
\only<4>{
To compute $(D_{\textbf{e}_\theta} f)(P)$ we use the circle centered at the origin and passing through $P(r_0,\theta_0)$. The polar parametrization of this circle that has \emph{unit} tangent at $P$ is given by $(r,\theta) = (r_0, \frac{1}{r_0}t)$. Therefore
%
$$b=(D_{\textbf{e}_\theta} f)(P) = \left. \frac{d}{dt}\right|_{t=\theta_0} f\left(r_0,\frac{1}{r_0}t\right) = \frac{1}{r_0} \frac{\partial f}{\partial \theta}(P)\; .$$}
%
\only<5>{From the previous computations:
%
$$(\nabla f)_P = \frac{\partial f}{\partial r}(P)\textbf{e}_r + \frac{1}{r_0} \frac{\partial f}{\partial \theta}(P)\textbf{e}_\theta \; ,$$
%
or
%
$$\nabla = \textbf{e}_r \frac{\partial }{\partial r} + \textbf{e}_\theta \frac{1}{r} \frac{\partial }{\partial \theta}\; .$$}
\end{overlayarea}
\end{frame}

\begin{frame}
  \frametitle{Application}
  Let $f$ be a function on the plane such that $f$ depends only on the distance to a fixed point, $O$.

\pause
  In a polar coordinate system with origin at $O$ we get $f(P) = g(r)$

  $$\nabla = \textbf{e}_r \frac{\partial }{\partial r} + \textbf{e}_\theta \frac{1}{r} \frac{\partial }{\partial \theta}\; .$$
%
$$\nabla f = g'(r) \textbf{e}_r = g'(r) \; \widehat{\textbf{r}} = \frac{g'(r)}{r}\, \textbf{r}\; .$$

\pause
\underline{Example}: $f(P) = |OP|^{-1}= r^{-1}=g(r)$. Then
%
$$\nabla f = g'(r)\textbf{e}_r = - r^{-2} \textbf{e}_r = -\frac{1}{r^3} \, \textbf{r}$$

\pause
\underline{Problem}: Let $\textbf{X}$ be a vector field of the form
%
$$\textbf{X} = h(r) \textbf{r}\; $$
%
for some continuous function $h$. Show that $\textbf{X}$ is a \emph{gradient field}: there exists a smooth function $f$ such that $\textbf{X} = \nabla f$.
\end{frame}

\begin{frame}
  \frametitle{Gravity and Gradient}

  Object at $(x_0,y_0,z_0 = f(x_0,y_0))$, moves along surface $z=f(x,y)$
  \pause

  Force: Component of $\textbf{G}= -mg\; \textbf{k}$ tangent to the surface

  \pause
  Normal to surface:
  %
  $$\textbf{n} = \langle -f_x(x_0,y_0), -f_y(x_0,y_0), 1\rangle = -\nabla f + \textbf{k}$$
  \pause
  $$\textbf{F} = \textbf{orth}_{\bm{n}} \textbf{G} =
  -mg \; \textbf{orth}_{\bm{n}} \textbf{k}$$
  \pause
  $$\textbf{orth}_{\bm{n}} \textbf{k} =
  \textbf{k} - \textbf{proj}_{\bm{n}} \textbf{k} =
  \textbf{k} - \frac{\textbf{k}\cdot \textbf{n}}{|\textbf{n}|^2} \, \textbf{n} =
  \textbf{k} - \frac{1}{|\textbf{n}|^2} (-\nabla f + \textbf{k})
  $$
\pause
Horizontal component of $\textbf{F}$:
%
$$\frac{mg}{1+|\nabla f|^2} (-\nabla f)$$
\pause
Gravity pulls object in the direction of fastest descent.

\pause
\underline{Question}: Is the object moving in that direction?

\end{frame}

\begin{frame}
  \frametitle{Optimization Problem}

  Function $f \colon D \to \mathbb{R}$ defined on a region $D$ in $\mathbb{R}^2$, we want to know:
%
\begin{itemize}
  \item The largest and the smallest values of $f$ attained on $D$, if any;
  %
  \item The points where these extreme values are attained.
\end{itemize}

\pause
A point $P_0$ in $D$ is a point of:
\begin{itemize}
  \item absolute maximum, if $f(P) \leqslant f(P_0)$ for all $P$ in $D$;
  \item absolute minimum, if $f(P) \geqslant f(P_0)$ for all $P$ in $D$.
\end{itemize}

\pause
These notions are relative to the domain $D$. A point $P_0$ that is not an extreme point might become one if we focus only around that point.

\pause
A point $P_0$ in $D$ is a point of:
\begin{itemize}
  \item local maximum, if there exists an open disk $B=B_r(P_0)$ centered at $P_0$ such that $f(P) \leqslant f(P_0)$ for all $P$ in $B \cap D$;
  \item local minimum, if there exists an open disk $B=B_r(P_0)$ centered at $P_0$ such that $f(P) \geqslant f(P_0)$ for all $P$ in $B \cap D$.
\end{itemize}

\pause
How do we find points of extreme?
\end{frame}

\begin{frame}
  \frametitle{Critical Points}

If $\textbf{u}=(\nabla f)(P_0)$ exists and is non-zero, then
\begin{itemize}
  \item $f$ increases along $\textbf{u}$;
  \item $f$ decreases along $-\textbf{u}$;
\end{itemize}
%
\pause
If we can move along $\pm\textbf{u}$ and stay in $D$, then $P_0$ is not an extreme.

\pause
If:
%
\begin{itemize}
  \item $P_0$ is a point of extreme (minimum or maximum);
  %
  \item $P_0$ is an \emph{interior point} of $D$, which means that there exists an open disk centered at $P_0$ and completely included in $D$;
  %
  \item directional derivatives at $P_0$ exist in all directions
\end{itemize}
%
then \pause $(\nabla f)(P_0) = \textbf{0}$. In particular, $f_x(P_0) = f_y(P_0) = 0$.\pause

\smallskip

\underline{Geometric Interpretation}: \pause At an interior point of extreme, the tangent plane to the graph surface is horizontal.\pause

\smallskip

\underline{The converse is not true}: \pause if $f_x(P_0) = f_y(P_0) = 0$, then $P_0$ is not necessarily a point of extreme.


\end{frame}

\begin{frame}
  \frametitle{}

Where else can one find extreme points?\pause

\begin{itemize}
  \item At points $P_0$ where some directional derivatives do not exist (suffices that one of $f_x(P_0)$ or $f_y(P_0)$ does not exist.);
  \item At points $P_0$ in $D$ that are not interior points of $D$.
\end{itemize}

\pause
\underline{Important concept}: A point $P$ in $\mathbb{R}^2$ is a \emph{boundary point} for a region $D$ if every open disk centered at $P$ has points both in $D$ and outside of $D$. Similar definition for $\mathbb{R}^3$, but replace open disk with open ball.

\pause
Examples:
\begin{itemize}
  \item $D$=open unit disk $\Longrightarrow$\pause set of boundary points = unit circle;\pause
  \item $D$=closed unit disk $\Longrightarrow$\pause set of boundary points = unit circle;\pause
\end{itemize}
%
Notice that a boundary point may or may not be included in $D$.

\pause
\underline{Strategy for finding extreme points}:
%
\begin{itemize}
  \item Check the \emph{critical points} of $f$:
  \begin{itemize}
    \item Points $P_0$ for which $f_x(P_0)$ or $f_y(P_0)$ does not exist;
    \item Points $P_0$ for which $f_x(P_0)=f_y(P_0)=0$.
  \end{itemize}
  %
  \item Check boundary points included in the domain.
\end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Example}

Find the extreme points of $f(x,y) = x^4+y^4-4xy$ on $D=\mathbb{R}^2$.

\begin{itemize}
  \item \pause  All points are interior points%
  %, so there are no boundary points included in the domain.
  %
  \item \pause The function is differentiable everywhere
  %, so directional derivatives exist at all points.
  %
  \item \pause It remains to check the points $(x,y)$ for which $f_x(x,y)=f_y(x,y)=0$.
  %
  $$\left\{ \begin{array}{ll}
    f_x(x,y) & = 0 \\
    %
    f_y(x,y) & = 0
  \end{array}
  \right.
  %
  \Longleftrightarrow
  %
  \left\{ \begin{array}{ll}
    4x^3-4y & = 0 \\
    %
    4y^3-4x & = 0
  \end{array}
  \right.
  %
  \Longleftrightarrow
  %
  \left\{ \begin{array}{ll}
    x^3 & = y \\
    %
    y^3 & = x
  \end{array}
  \right. $$
  %
  \item \pause Solve the system.
  \begin{itemize}
    \item \pause Bad news: \pause This is a non-linear system, and there is no general method for solving non-linear systems.
    %
    \item \pause Good news: \pause THIS system is not that bad.\pause
  \end{itemize}
  %
  There are THREE values of $x$ that work:
  %
  \begin{align*}
    x=0 \Longrightarrow y=0 \Longrightarrow \text{ Point } (0,0)\\
    %
    x=1 \Longrightarrow y=1 \Longrightarrow \text{ Point } (1,1) \\
    %
    x=-1 \Longrightarrow y=-1 \Longrightarrow \text{ Point } (-1,-1)
  \end{align*}
  %
  \pause Typical mistake: \pause $x^9 = x \Longleftrightarrow x^8=1$.
\end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Second Derivative Test}

Which of the three points are points of minimum/maximum?\pause

\emph{Hessian matrix} of $f$ at $P(x_0,y_0)$:
%
$$H(x_0,y_0) = \left(\!
\begin{array}{cc}
  f_{xx}(x_0,y_0) & f_{xy}(x_0,y_0) \\
  %
  f_{yx}(x_0,y_0) & f_{yy}(x_0,y_0)
\end{array}\!
 \right)\; $$
%
$$D(x_0,y_0) = f_{xx}(x_0,y_0) f_{yy}(x_0,y_0) - (f_{xy}(x_0,y_0))^2\; $$
%

\pause
\underline{Test}: Let $P(x_0,y_0)$ be an interior critical point of $f$ and suppose that $f$ has continuous second order derivatives around $P$. If:
%
\begin{itemize}
  \item \pause $D(x_0,y_0)>0$ and $f_{xx}(x_0,y_0)>0$, then $(x_0,y_0)$ is a local minimum;

      Example: Critical point $(0,0)$ for the function $f(x,y)=x^2+y^2$.

  \item \pause $D(x_0,y_0)>0$ and $f_{xx}(x_0,y_0)<0$, then $(x_0,y_0)$ is a local maximum;

      Example: Critical point $(0,0)$ for the function $f(x,y)=-x^2-y^2$.

  \item \pause $D(x_0,y_0)<0$, then $(x_0,y_0)$ is neither a minimum nor a maximum;

  Critical points that are not extreme points are called \emph{saddle points}.

        Example: Critical point $(0,0)$ for the function $f(x,y)=x^2-y^2$.

  \item \pause $D(x_0,y_0)=0$, then the test is inconclusive:

  Examples: $x^4+y^4$, $-x^4-y^4$, $x^4-y^4$

\end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Back to Example}

In the example of $f(x,y) = x^4+y^4-4xy$ we have
%
\begin{itemize}
  \item $f_{xx} = 12x^2$;
  \item $f_{xy} = -4$;
  \item $f_{yy}=12y^2$;
  \item $D= f_{xx}f_{yy}-f_{xy}^2 = 144x^2y^2-16$
\end{itemize}

\pause
At the critical points:

\begin{tabular}{|c|c|c|c|c|c|}
    \hline
    % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
    $(x_0,y_0)$ & $f_{xx}(x_0,y_0)$ & $f_{yy}(x_0,y_0)$ & $f_{xy}(x_0,y_0)$ & $D(x_0,y_0)$ &  Conclusion \\
    \hline
    (0,0) & 0 & 0 & -4 & $-16 <0$ & Saddle point  \\
    \hline
    (1,1) & 12 & 12 & -4 & $144-16 > 0$ & Local min  \\
    \hline
    (-1,-1) & 12 & 12 & -4 & $144-16 > 0$ & Local min \\
    \hline
  \end{tabular}

\medskip
\pause
In this case it turns out that the two local minimum points are actually global minimum points, because
%
$$f(x,y) = x^4+y^4-4xy = (x^2-1)^2+(y^2-1)^2+2(x-y)^2 -2  \geqslant -2\; .$$

\pause
But in general, global extreme points may not exist.
\end{frame}

\begin{frame}
  \frametitle{Extreme Value Theorem}

Global extreme points are guaranteed to exist if:

\begin{itemize}
  \item $f \colon D \to \mathbb{R}$ is continuous, and
  \item the domain $D$ has the following properties:
  %
  \begin{itemize}
    \item $D$ is \emph{bounded}: The points in $D$ don't go farther than a certain fixed, finite distance from a fixed point.
    \item $D$ is \emph{closed}: $D$ contains all its boundary points.
  \end{itemize}
\end{itemize}
%

This statement above is the \textbf{Extreme Value Theorem}

\begin{itemize}
  \item \pause Why does $D$ have to be bounded: \pause to exclude $f\colon \mathbb{R}^2 \to \mathbb{R}$, $f(x,y) = x$;
  \item \pause Why does $D$ have to be closed: \pause to exclude $f\colon \mathbb{R}^2\setminus\{(0,0)\} \to \mathbb{R}$, $f(x,y) = (x^2+y^2)^{-1}$. In this situation the boundary of $D$ is $\{(0,0)\}$ and is not included in $D$, so $D$ is not closed.
\end{itemize}
\end{frame}
