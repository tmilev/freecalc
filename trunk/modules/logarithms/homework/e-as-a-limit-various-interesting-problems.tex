$1,000,000$ servers are handling Internet users. Suppose we distribute the computation load as follows. The computation load distributing program directs every new user to a server chosen at random (one server is allowed to process more than one user at a time). Suppose one server has defective hardware and crashes. We are testing the system by simulating $X$ Internet users.
\begin{itemize}
\item What is the chance we catch the defective server using $1$ simulated user?
\item Without using a calculator, estimate the chance we fail to catch the defective server using $1,000,000$ simulated users.
\item Using a calculator, estimate the chance we fail to catch the defective server using $100,000$ simulated users. Write an expression using $e$ which approximates this chance. Evaluate the latter with a calculator. Are the two numbers close? 
\end{itemize}

\textbf{Remark.} While such a simple system architecture would not be practical, it is not to be immediately dismissed as terrible. For example, if we need to handle 2 million users per second, our load distributing mechanism might not be fast enough to keep track of each server's load. On the other hand, an inexpensive modern pc will easily generate 2 million random numbers per second.
